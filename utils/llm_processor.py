"""
Module pour l'extraction de donnÃ©es structurÃ©es avec Ollama LLM
Utilise l'API structurÃ©e d'Ollama avec Pydantic pour une validation robuste
"""

from typing import List, Optional
from pydantic import BaseModel, Field, ValidationError
from ollama import chat


class ProductExtraction(BaseModel):
    """
    SchÃ©ma Pydantic pour un produit extrait
    """
    product_identifier: str = Field(
        ..., 
        description="SKU, code produit ou identifiant unique",
        min_length=1,
        max_length=255
    )
    name: str = Field(
        ..., 
        description="Nom du produit",
        min_length=1,
        max_length=500
    )
    price: float = Field(
        ..., 
        description="Prix du produit (nombre dÃ©cimal positif)",
        gt=0.0
    )
    currency: str = Field(
        default="DT", 
        description="Code devise ISO (DT,TND, EUR,USD,$, etc.)",
        max_length=3
    )
    category: Optional[str] = Field(
        None, 
        description="CatÃ©gorie du produit",
        max_length=255
    )
    description: Optional[str] = Field(
        None, 
        description="Description dÃ©taillÃ©e du produit"
    )
    product_url: Optional[str] = Field(
        None, 
        description="URL complÃ¨te de la page produit"
    )
    image_url: Optional[str] = Field(
        None, 
        description="URL de l'image principale du produit"
    )
    is_available: bool = Field(
        default=True, 
        description="DisponibilitÃ© du produit (en stock ou non)"
    )
  
class LLMResponse(BaseModel):
    """
    SchÃ©ma Pydantic pour la rÃ©ponse complÃ¨te du LLM
    """
    products: List[ProductExtraction] = Field(
        default_factory=list,
        description="Liste des produits extraits"
    )
    promotions: List[str] = Field(
        default_factory=list,
        description="Liste des promotions dÃ©tectÃ©es"
    )

def extract_products_with_llm(text_batch: str, competitor_base_url: str, model: str = 'llama3.1') -> LLMResponse:
    """
    Extrait les produits d'un texte en utilisant Ollama avec sortie structurÃ©e
    
    Args:
        text_batch: Texte nettoyÃ© Ã  analyser
        competitor_base_url: URL du site concurrent (pour contexte)
        model: Nom du modÃ¨le Ollama Ã  utiliser (dÃ©faut: llama3.1)
    
    Returns:
        LLMResponse: Objet Pydantic contenant les produits et promotions extraits
    """
    
    # Prompt optimisÃ© pour l'extraction structurÃ©e
    system_prompt = """Tu es un expert en extraction de donnÃ©es pour l'e-commerce.
Ta mission est d'analyser du texte provenant de sites web concurrents et d'extraire TOUTES les informations produits de maniÃ¨re structurÃ©e et prÃ©cise.

RÃˆGLES STRICTES:
1. Extrais uniquement les informations prÃ©sentes dans le texte
2. Ne gÃ©nÃ¨re JAMAIS de donnÃ©es fictives ou inventÃ©es
3. Si un champ est incertain, utilise null
4. Pour les prix, extrais uniquement la valeur numÃ©rique (retire symboles et espaces)
5. Identifie le code produit (SKU, rÃ©fÃ©rence, modÃ¨le) comme product_identifier
6. DÃ©tecte les promotions et offres spÃ©ciales sÃ©parÃ©ment

FORMAT DE SORTIE:
Le JSON doit suivre exactement ce schÃ©ma avec ces champs obligatoires:
- products: liste d'objets avec (product_identifier, name, price, currency, category?, description?, product_url?, image_url?, is_available)
- promotions: liste de textes dÃ©crivant les offres promotionnelles dÃ©tectÃ©es"""

    user_prompt = f"""Analyse le texte suivant provenant du site: {competitor_base_url}

TEXTE Ã€ ANALYSER:
{text_batch[:5000]} 

Extrait TOUS les produits avec leurs informations complÃ¨tes."""

    try:
        # Appel Ã  l'API Ollama avec schÃ©ma structurÃ© (nouvelle API)
        response = chat(
            model=model,
            messages=[
                {
                    'role': 'system',
                    'content': system_prompt
                },
                {
                    'role': 'user',
                    'content': user_prompt
                }
            ],
            format=LLMResponse.model_json_schema(),  # Force le LLM Ã  suivre le schÃ©ma Pydantic
            options={
                'temperature': 0.1,      # TrÃ¨s dÃ©terministe pour extraction de donnÃ©es
                'top_p': 0.9,
                'num_predict': 800,     # Limite de tokens gÃ©nÃ©rÃ©s
            }
        )
        
        # Extraction du contenu de la rÃ©ponse
        raw_content = response['message']['content']
        print(f"RÃ©ponse LLM brute reÃ§ue: {raw_content[:2500]}")
        
        # Validation avec Pydantic
        try:
            validated_response = LLMResponse.model_validate_json(raw_content)
            print(f"âœ… Extraction rÃ©ussie: {len(validated_response.products)} produits trouvÃ©s")
            print(f"produits trouvÃ©s: {validated_response}")
            return validated_response
            
        except ValidationError as e:
            print(f"âŒ Erreur de validation Pydantic: {e}")
            print(f"Contenu brut qui a Ã©chouÃ©: {raw_content[:2500]}")
            # Retourner une rÃ©ponse vide plutÃ´t que de crasher
            return LLMResponse(products=[], promotions=[])

    except Exception as e:
        print(f"âŒ Erreur lors de l'appel Ollama: {type(e).__name__}: {e}")
        return LLMResponse(products=[], promotions=[])


def test_llm_extraction():
    """
    Fonction de test pour vÃ©rifier le bon fonctionnement du LLM
    Ã€ exÃ©cuter manuellement depuis le shell Django
    """
    sample_text = """
    iPhone 15 Pro Max 256GB - Prix: 1199.99 EUR
    RÃ©fÃ©rence: IPHONE15PM256
    
    Description: Le dernier smartphone Apple avec puce A17 Pro
    CatÃ©gorie: Smartphones
    En stock
    
    Samsung Galaxy S24 Ultra - 999.00 EUR
    SKU: SAMS24ULTRA
    Disponible en noir et gris
    
    PROMOTION SPÃ‰CIALE: -20% sur tous les accessoires ce week-end!
    """
    
    print("ðŸ§ª Test d'extraction LLM...")
    result = extract_products_with_llm(sample_text, "https://example.com")
    
    print(f"\nðŸ“Š RÃ©sultats:")
    print(f"ðŸ›’ Produits extraits: {result.products}")
    print(f"\nðŸŽ Promotions: {result.promotions}")
    
    return result


# Pour utiliser dans Django shell:
# python manage.py shell
# >>> from utils.llm_processor import test_llm_extraction
# >>> test_llm_extraction()
